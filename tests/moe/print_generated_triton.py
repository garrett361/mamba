from argparse import ArgumentParser

import torch

from mamba_ssm.modules.moe import _get_counts

"""
Tiny script for printing out the triton code generated by compile.
"""


@torch.compile()
def fn(
    indices: torch.Tensor, n_routed_experts: int, alignment: int
) -> tuple[torch.Tensor, torch.Tensor]:
    counts = _get_counts(indices, n_routed_experts)
    counts_aligned = ((counts + alignment - 1) // alignment) * alignment
    offs = counts_aligned.cumsum(dim=0, dtype=torch.int32)

    # Build the aligned index map
    idxs_offs_align = (counts_aligned - counts).roll(1)
    idxs_offs_align[0] = 0
    idxs_offs_align = idxs_offs_align.cumsum(dim=0)
    idxs = torch.arange(counts.sum(), device=counts.device)
    idxs = idxs + idxs_offs_align.repeat_interleave(counts)
    return idxs, offs


if __name__ == "__main__":
    torch._dynamo.reset()
    torch.compiler.reset()
    torch._logging.set_logs(output_code=True)
    parser = ArgumentParser()
    parser.add_argument("--warmups", type=int, default=3)
    parser.add_argument("--reps", type=int, default=16)
    parser.add_argument("--in_features", type=int, default=3072)
    parser.add_argument("--d_intermediate", type=int, default=1344)
    parser.add_argument("--n_routed_experts", type=int, default=64)
    parser.add_argument("--n_activated_experts", type=int, default=8)
    parser.add_argument("--n_shared_experts", type=int, default=0)
    parser.add_argument("--bsz", type=int, default=4)
    parser.add_argument("--seqlen", type=int, default=4096)
    parser.add_argument("--alignment", type=int, default=4096)

    args = parser.parse_args()

    indices = (
        torch.randn(
            args.seqlen,
            args.n_routed_experts,
            device="cuda",
        )
        .topk(args.n_activated_experts, dim=-1)
        .indices
    )
    fn(indices, args.n_routed_experts, args.alignment)
